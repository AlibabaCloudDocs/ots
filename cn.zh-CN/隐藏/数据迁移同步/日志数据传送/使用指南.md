# 使用指南 {#concept_b31_mxs_lgb .task}

本章节主要介绍如何使用日志数据传送服务。

## 服务详情查看 {#section_jmm_xdt_lgb .section}

1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
2.  单击页面左侧的**Swarm** \> **服务** ，进入服务列表。
3.  单击服务名称栏下面的服务名称（如示例中创建的 loghub-shipper），进入服务详情页面。请根据需要，在**容器**列表栏中执行如下操作：
    -   查看服务日志

        单击操作栏下的**日志**，查看传送服务的实时日志。

    -   查看运行状态及报警规则
        1.  单击操作栏下的**监控**，查看容器的运行状态。
        2.  单击**查看历史监控数据/设置报警规则**，查看监控图表和报警规则。您还可以在该页面创建报警规则。

## 使用示例 {#section_ngs_xdt_lgb .section}

以使用如下的配置为例：

``` {#codeblock_mhk_oz7_ihe}
loghub:{"endpoint":"https://lhshipper-test.cn-hangzhou.log.aliyuncs.com", "logstore":"test-store","consumer_group":"defaultcg"}
tablestore:{"endpoint":"https://lhshipper-test.cn-hangzhou.ots.aliyuncs.com", "instance":"lhlshipper-test", "target_table":"loghub_target", "status_table":"loghub_status"}
exclusive_columns: ["__source__", "__time__"]
transform: {"rename":"original", "trans-pkey":"(->int 10 original)"}
```

## 写入数据 {#section_kps_xdt_lgb .section}

使用日志服务的 API 在日志服务中写入一条数据，如下所示：

``` {#codeblock_tdt_gmf_mvc}
LogItem log = new LogItem();
log.PushBack("original", "12345");
log.PushBack("keep", "hoho");
ArrayList logs = new ArrayList<LogItem>();
logs.add(log);
loghub.PutLogs("lhshipper-test", "test-store", "smile", logs, "");
```

这条日志有两个用户字段，其中 original 字段的值为 12345，keep 字段的值为 hoho。此外，还有三个日志服务添加的字段，其中 topic 为 smile，而 \_\_source\_\_ 和 \_\_time\_\_ 字段随环境变化而变化。

 **数据查看** 

使用工具马上可以看到表格存储中数据表已经有了一条数据（转成 json 格式方便描述）。

``` {#codeblock_3ri_s66_9pj}
[{"rename": "12345", "trans-pkey": 12345, "keep": "hoho"},
{"__topic__": "smile", "original": "12345"}]
```

其中，rename、trans-pkey、keep 为主键列，\_\_topic\_\_ 与 original 为属性列。

根据环境变量中的配置：

-   在 transform 中定义 `"rename": "original"`，日志数据中 original 的值为 12345，因此表格存储中该行的 rename 的值也为 12345。
-   在 transform 中定义 `"trans-pkey": "(->int 10 original)"`，传送服务将 original 的值以十进制的方式转成整数写入表格存储中的 trans-pkey 列。
-   keep 没有任何转换规则，在表格存储中，属性类 keep 的值与日志数据中的保持一致。
-   日志数据中的 \_\_source\_\_ 和 \_\_time\_\_ 字段由于在 exclusive\_columns 中配置了 \[“\_\_source\_\_“, “\_\_time\_\_“ \]，这两个字段的数据不会写入数据表中。
-   \_\_topic\_\_ 和 original 两个字段以属性列的方式写入数据表。

 **同步状态查询** 

每个传送服务的进程每隔 5 分钟会在状态表中添加一行状态数据，状态数据示例如下（转成 json 格式方便描述）：

``` {#codeblock_5w9_d16_qt4}
[{"project_logstore": "lhshipper-test|test-store", "shard": 0, "target_table": "loghub_target", "timestamp": 1469100705202},
{"skip_count": 0, "shipper_id": "fb0d62cacc94-loghub-shipper-loghub-shipper-1", "cu_count": 1, "row_count": 1, "__time__": 1469100670}]
```

其涵义为传送服务的某个 worker（”shipper\_id”: “fb0d62cacc94-loghub-shipper-loghub-shipper-1”）， 在 2016-07-21 T11:31:45.202000Z 添加了这条状态（”timestamp”: 1469100705202）。

在之前的 5 分钟里，该 worker 从名为 **lhshipper-test** 的日志 Project 中的 **test-store**这个 Logstore（**“project\_logstore”: “lhshipper-test|test-store”**）0 号 Shard（**“shard”: 0**）消费了 1 条日志，其中跳过日志 0 条（**“skip\_count”: 0**），向数据表写入 1 条日志（**“row\_count”: 1**），消耗了 1 个 CU（**“cu\_count”: 1**）。

 **错误格式日志提醒** 

在状态表中，会给出最近 5 分钟内跳过日志的条数信息，这是因为系统异常或者系统升级等会不可避免地输出一些不符合格式规范的日志数据，导致传送服务无法对这些日志进行转换，这部分日志则会被跳过。

例如写入如下的日志数据：

``` {#codeblock_3eb_1zw_05r}
LogItem log = new LogItem()
log.PushBack("original", "abcd")
log.PushBack("keep", "hoho")
ArrayList logs = new ArrayList<LogItem>()
logs.add(log)
loghub.PutLogs("lhshipper-test", "test-store", "smile", logs, "")
```

由于在环境设置中将日志中的 original 字段转成整数写入数据表中的 trans-pkey 列，但是该条日志中 original 并不是一个数字，所以状态表中的数据如下：

``` {#codeblock_hzb_g6y_mom}
[{"project_logstore": "lhshipper-test|test-store", "shard": 0, "target_table": "loghub_target", "timestamp": 1469102805207},
{"skip_sample": "{\"__time__\":1469102565,\"__topic__\":\"smile\",\"__source__\":\"10.0.2.15\",\"original\":\"abcd\",\"keep\":\"hoho\"}", "skip_count": 1, "shipper_id": "fb0d62cacc94-loghub-shipper-loghub-shipper-1", "cu_count": 0, "row_count": 0, "__time__": 0}]
```

在状态表中，skip\_count 为 1，属性列 skip\_sample 表示被忽略的原始日志数据。

同时，在容器服务的日志中也可以查看到如下的日志信息：

``` {#codeblock_z65_zri_sdn}
loghub-shipper_loghub-shipper_1 | 2016-07-21T12:02:56.113581003Z 12:02:56.111 [pool-4-thread-3] ERROR shipper.error - abcd is not 10-based int
loghub-shipper_loghub-shipper_1 | 2016-07-21T12:02:56.114039933Z 12:02:56.111 [pool-4-thread-3] INFO  shipper.core - skip 1 rows
loghub-shipper_loghub-shipper_1 | 2016-07-21T12:02:56.139854766Z 12:02:56.139 [pool-4-thread-3] INFO  shipper.core - skip: {"__time__" 1469102565, "__topic__" "smile", "__source__" "10.0.2.15", "original" "abcd", "keep" "hoho"}
```

可以看到，日志中详细描述了该数据被跳过的原因为：abcd is not 10-based int。

## 改变配置 {#section_wct_pqt_lgb .section}

1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
2.  单击**服务**，进入服务页面。
3.  找到传送服务，单击其右侧操作栏下的**变更配置**，进入修改页面。
4.  单击**确定**。

## 升级镜像 {#section_ub3_rqt_lgb .section}

1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
2.  单击**应用**，进入应用页面。
3.  找到传送服务，单击其右侧操作栏下的**重新部署**。
4.  单击**确定**。

## 扩容和缩容 {#section_zls_rqt_lgb .section}

传送服务具有良好的扩展性，会自动根据容器实例的数量进行 Shard 分配，当传送服务的数据传送能力达不到业务要求时，可以方便地进行扩容与缩容。

 **扩容** 

以下是两种有效的扩容方式。如果用户需要频繁扩容、缩容，可以考虑使用[弹性伸缩](../../../../cn.zh-CN/产品简介/什么是弹性伸缩.md)以及[资源编排](../../../../cn.zh-CN/产品简介/什么是资源编排服务？.md)。

-   增加节点：
    1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
    2.  单击**集群**，进入集群列表页面。
    3.  找到传送服务所在的集群，单击其右侧操作栏下的**管理**。
    4.  单击页面右侧的**集群扩容**增加按量付费的云服务器，或者单击**添加已有节点**将已有的的云服务器加入集群。

        **说明：** 更多关于添加已有节点，参见[添加已有云服务器](../../../../cn.zh-CN/用户指南/集群管理/添加已有节点.md)。

-   增加传送服务的容器：增加集群节点本身并不会增加传送服务的容器，增加传送服务容器需在改变传送服务的配置，其操作步骤如下：
    1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
    2.  单击**服务**，进入服务页面。
    3.  **找到传送服务，单击其右侧操作栏下的**变更配置，进入修改页面。
    4.  修改容器数量，然后单击**确定**。

 **缩容** 

缩容的步骤和扩容相反，步骤如下：

1.  登录[容器服务控制台](https://cs.console.aliyun.com/)。
2.  单击页面左侧的**服务**，进入服务列表页面。
3.  单击传送服务右侧操作栏下的**变更配置**，进入更新服务页面。
4.  减少**容器数量**。
5.  单击**确定**，返回服务列表页面。
6.  单击传送服务右侧操作栏下的**重新调度**。
7.  单击页面左侧的**节点**，进入节点列表页面。
8.  找到容器减少的云服务器，并单击其右侧操作栏下的**更多** \> **移除节点** 。
9.  和扩容不同，容器服务并不会主动释放摘除的云服务器。需要您去 ECS 控制台手工释放。

