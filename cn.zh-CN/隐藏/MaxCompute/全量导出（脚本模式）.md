# 全量导出（脚本模式） {#concept_msn_1wz_cfb .task}

数据集成（Data Integration）产品提供数据同步服务，有向导模式和脚本模式两种方式。向导模式更简单，脚本模式更灵活。本文主要介绍如何将表格存储中的全量数据（Put/Update/Delete）通过数据集成全量导出到MaxCompute中。

## 步骤一： 新增数据源 {#section_i7d_g59_b3i .section}

将表格存储数据库添加为新增数据源，具体操作如下：

1.  以项目管理员身份登录[DataWorks控制台](https://workbench.data.aliyun.com/console)。 

    **说明：** 仅项目管理员角色可以新建数据源，其他角色的成员仅可查看数据源。

2.  找到目标工作空间，单击**进入数据集成**。
3.  选择**同步资源管理** \> **数据源**，单击**新增数据源**。
4.  在新增数据源弹出框中，选择数据源类型为**Tablestore**。
5.  在弹出的窗口中，填写配置。 

    ![将MaxCompute数据同步到表格存储](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1068405/156887342352793_zh-CN.png)

    |参数|说明|
    |--|--|
    |数据源名称|数据源的名称，例如，gps\_data。|
    |Endpoint|填入目标Tablestore实例的[服务地址](../cn.zh-CN/开发指南/基础概念/服务地址.md#)。     -   如果Tablestore的实例和MaxCompute在同一个region，填入私网地址。
    -   如果Tablestore的实例和MaxCompute不在同一个region，填入公网地址。
    -   不能填入VPC地址。
 |
    |Tablestore实例ID|Tablestore的实例的名称。|
    |Access Id|登录账户的AccessKeyID。获取方式参见[创建AccessKey](../cn.zh-CN/通用参考/创建AccessKey.md#)。|
    |Access Key|登录账户AccessKeyID对应的AccessKeySecret。获取方式参见[创建AccessKey](../cn.zh-CN/通用参考/创建AccessKey.md#)。|

6.  单击**测试连通性**。
7.  单击**完成**，在**数据源**页面会出现该数据源信息。

## 步骤二 创建MaxCompute数据源 {#section_bht_3wz_cfb .section}

本操作与步骤一类似，只是选择MaxCompute作为数据源。

本示例中，该数据源名称使用OTS2ODPS。

## 步骤三 创建全量导出通道 {#section_a25_mwz_cfb .section}

1.  在[大数据开发套件](https://di-cn-shanghai.data.aliyun.com/#/)页面单击**同步任务**。
2.  选择**脚本模式**。
3.  在弹出的导入模板对话框中，**来源类型**选择OTS，**目标类型**选择ODPS。
4.  单击**确认**，进入配置页面。
5.  设置配置参数。 

    ``` {#codeblock_j3j_jjj_6xh}
    {
    "type": "job",
    "version": "1.0",
    "configuration": {
    "setting": {
      "errorLimit": {
        "record": "0"    # 能够允许的最大错误数
      },
      "speed": {
        "mbps": "1",   # 最大的流量，单位MB。
        "concurrent": "1"  # 并发数。
      }
    },
    "reader": {
      "plugin": "ots",  # 读取的插件名称
      "parameter": {
        "datasource": "",  # 数据源名称
        "table": "",  # 表名
        "column": [  # 需要导出到MaxCompute中去的表格存储中的列名
          {
            "name": "column1"
          },
          {
            "name": "column2"
          },
          {
            "name": "column3"
          },
          {
            "name": "column4"
          },
          {
            "name": "column5"
          }
        ],
        "range": {  # 需要导出的数据范围，如果是全量导出，则需要从INF_MIN到INF_MAX
          "begin": [ # 需要导出数据的起始位置，最小的位置是INF_MIN。begin中的配置项数目个数和表格存储中相应表的主键列个数一致。
            {
              "type": "INF_MIN"
            },
            {
              "type": "INF_MIN"
            },
            {
              "type": "STRING",  # 这个配置项的意思是：第三列的起始位置是begin1。
              "value": "begin1"
            },
            {
              "type": "INT",  # 这个配置项的意思是：第四列的起始位置是0。
              "value": "0"
            }
          ],
          "end": [  # 导出数据的结束位置
            {
              "type": "INF_MAX"
            },
            {
              "type": "INF_MAX"
            },
            {
              "type": "STRING",
              "value": "end1"
            },
            {
              "type": "INT",
              "value": "100"
            }
          ],
          "split": [  # 这一项配置分区范围，一般可以不配置，如果性能较差，可以提工单或者加入钉钉群：11789671 找工作人员协助您设置
            {
              "type": "INF_MIN"
            },
            {
              "type": "STRING",
              "value": "splitPoint1"
            },
            {
              "type": "STRING",
              "value": "splitPoint2"
            },
            {
              "type": "STRING",
              "value": "splitPoint3"
            },
            {
              "type": "INF_MAX"
            }
          ]
        }
      }
    },
    "writer": {
      "plugin": "odps",  # MaxCompute写入的插件名
      "parameter": {
        "datasource": "",  # MaxCompute的数据源名称
        "column": [],  # MaxCompute中的列名，这个列名顺序对应TableStore中的列名顺序
        "table": "",  # MaxCompute中的表名，需要提前创建好，否则任务会失败。
        "partition": "",  # 如果表为分区表，则必填。如果表为非分区表，则不能填写。需要写入数据表的分区信息，必须指定到最后一级分区。
        "truncate": false  # 是否清空之前的数据
      }
    }
    }
    }
    ```

    **说明：** 详细的配置参数可参考[配置Table Store（OTS） Reader](../../../../../cn.zh-CN/数据汇聚/数据集成/作业配置/配置Reader插件/配置Table Store（OTS） Reader.md#)和[配置MaxCompute Writer](../../../../../cn.zh-CN/数据汇聚/数据集成/作业配置/配置Writer插件/配置MaxCompute Writer.md#)。

6.  单击**保存**，保存任务。

## 步骤四 运行任务（测试） {#section_mzw_l11_dfb .section}

1.  单击页面上方的**运行**，开始执行任务。 

    如果配置里面没有变量，则会立即执行。如果有变量，则会要求填入变量的真实值，单击**确认**后开始运行。

2.  运行结束后，在日志中可以查看任务是否成功和导出的数据行数。

## 步骤五 设置调度参数 {#section_11b_g7w_l5o .section}

1.  单击**数据开发**。
2.  在任务开发页签中，双击打开已创建的任务OTStoODPS。
3.  单击**调度配置**，设置调度参数。 

    按照如下参数配置后，任务会从第二天开始执行。

    参数说明如下：

    |参数|说明|
    |:-|:-|
    |调度状态|默认不勾选，表示执行。|
    |出错重试|建议勾选，表示出错后会重试。|
    |生效日期|建议使用默认值。|
    |调度周期|本示例中，选择分钟。|
    |开始时间|本示例中，设为00时00分。|
    |调度间隔|本示例中，选择5分钟。|
    |结束时间|本示例中，设为23时59分。|
    |依赖属性|在**依赖属性**区域，根据业务情况填写，或者使用默认值。|
    |跨周期依赖|在**跨周期依赖**区域，根据业务情况填写，或者使用默认值。|

4.  单击**参数配置**。 

    参数说明如下：

    |参数|说明|
    |:-|:-|
    |$\{bdp.system.bizdate\}|无需配置。|
    |startTime|在调度配置中设置**开始时间**的变量。在本示例中，设为$\[yyyymmddhh24miss-10/24/60\]，表示调度任务开始的时间减去10分钟。|
    |endTime|在调度配置中设置**结束时间**的变量。在本示例中，设为$\[yyyymmddhh24miss-5/24/60\]，表示调度任务开始的时间减去5分钟。|


## 步骤六 提交任务 {#section_fdf_4c1_dfb .section}

单击顶部菜单栏中的提交图标，将同步任务提交至调度系统中。调度系统会根据配置的属性，自动定时执行。

## 步骤七 查看任务 {#section_fgk_xc1_dfb .section}

1.  单击**运维中心**。
2.  在左侧导航栏中，选择**任务列表** \> **周期任务**，可以查看新建的任务OTStoODPS。

任务会从第二天的00点00分开始执行。

-   在左侧导航栏中，选择**任务运维** \> **周期实例**，查看当天需要运行的周期任务。单击实例名称，可以查看详情。

-   当单个任务在运行中或运行结束后可以查看日志。


## 步骤八 查看导入到MaxCompute中的数据 {#section_cbd_md1_dfb .section}

1.  单击**数据管理**。
2.  在左侧导航栏，单击**查找数据**，会列出MaxCompute中的所有表。
3.  找到刚刚导入数据的表（ots\_gps\_data），单击后进入该表的详情页。
4.  单击**数据预览**页签，查看导入的数据。

