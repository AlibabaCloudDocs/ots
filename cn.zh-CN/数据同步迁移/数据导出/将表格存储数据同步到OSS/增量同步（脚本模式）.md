# 增量同步（脚本模式）

通过DataWorks控制台将表格存储中的增量数据同步到OSS中。

## 步骤一：新增表格存储数据源

如果已新增表格存储数据源，请跳过此步骤。

新增表格存储数据源的操作请参见[步骤一：新增表格存储数据源](/cn.zh-CN/数据同步迁移/数据导出/将表格存储数据同步到OSS/全量导出（脚本模式）.md)。

## 步骤二：新增OSS数据源

如果已新增OSS数据源，请跳过此步骤。

新增OSS数据源的操作请参见[步骤二：新增OSS数据源](/cn.zh-CN/数据同步迁移/数据导出/将表格存储数据同步到OSS/全量导出（脚本模式）.md)。

## 步骤三：配置定时同步任务

新建并配置表格存储到OSS的增量数据同步任务，具体操作步骤如下：

1.  进入数据集成。

    1.  以项目管理员身份登录[DataWorks控制台](https://workbench.data.aliyun.com/console)。

        **说明：** 仅项目管理员角色可以新增数据源，其他角色的成员仅可查看数据源。

    2.  选择地域，在左侧导航栏，单击工作空间列表。

    3.  在工作空间列表页面，单击工作空间操作区域的**进入数据集成**。

2.  新建同步任务节点。

    每个同步任务都需创建一个相应的节点。

    1.  在数据集成控制台的首页，单击**新建离线同步**。

    2.  在新建节点对话框，输入节点名称，选择一个目标文件夹。

        ![fig_oss_001](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/5262197061/p198829.png)

    3.  单击**提交**。

3.  配置数据源。

    1.  在**数据集成**节点下，双击同步任务节点。

    2.  在同步任务节点的编辑页面的选择数据源区域，配置数据来源和数据去向。

        -   配置数据来源。

            选择**数据来源**的**数据源**为**OTS Stream**，选择数据源和数据表，可根据需要配置任务开始时间、结束时间、状态表的名称、最大重试次数等。

        -   配置数据去向。

            选择**数据去向**的**数据源**为**OSS**，选择数据源，配置Object前缀、文本类型、列的分隔符等。

        ![fig_oss_002](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/6689939061/p198831.png)

    3.  单击![script](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/7548388951/p127620.png)图标，进行脚本配置。

        使用过程时涉及OTSStream Reader和OSS Writer插件的配置。具体操作，请参见[配置OTSStream Reader](配置OTSStream Readert1840948.dita#concept_m4h_5gr_p2b)和[配置OSS Writer]()。

        在脚本配置页面，请根据如下示例完成配置。

        ```
        {
        "type": "job",
        "version": "1.0",
        "configuration": {
        "setting": {
        "errorLimit": {
         "record": "0"  # 允许出错的个数，当错误超过这个数目的时候同步任务会失败。
        },
        "speed": {
         "mbps": "1",  # 每次同步任务的最大流量。
         "concurrent": "1"   # 每次同步任务的并发度。
        }
        },
        "reader": {
        "plugin": "otsstream",  # Reader插件的名称。
        "parameter": {
         "datasource": "", # Tablestore的数据源名称，如果有此项则无需配置endpoint，accessId，accessKey和instanceName。
         "dataTable": "", # Tablestore中的数据表名称。
         "statusTable": "TablestoreStreamReaderStatusTable", # 存储Tablestore Stream状态的表，一般无需修改。
         "startTimestampMillis": "",  # 开始导出的时间点，由于是增量导出，需要循环启动此任务，则此处每次启动时的时间都不同，因此需要设置一个变量，例如${start_time}。
         "endTimestampMillis": "",  # 结束导出的时间点。此处也需要设置一个变量，例如${end_time}。
         "date": "yyyyMMdd",  # 导出该日期的数据，此功能与startTimestampMillis和endTimestampMillis重复，需要删除。
         "mode": "single_version_and_update_only", # Tablestore Stream导出数据的格式，目前需要设置为single_version_and_update_only。如果配置模板中无此项，则需要增加。
         "column":[  # 设置数据表中需要导出到OSS中的列，如果配置模板中无此项则需要增加，具体列个数由用户自定义设置。
                  {
                     "name": "uid"  # 列名，此处是Tablestore中的主键。
                  },
                  {
                     "name": "name"  # 列名，此处是Tablestore中的属性列。
                  },
         ],
         "isExportSequenceInfo": false, # single_version_and_update_only模式下只能设置为false。
         "maxRetries": 30 # 最大重试次数。
        }
        },
        "writer": {
        "plugin": "oss", # Writer插件的名称。
        "parameter": {
         "datasource": "", # OSS的数据源名称。
         "object": "",  # 备份到OSS的文件名前缀，建议使用"Tablestore实例名/表名/date"，例如"instance/table/{date}"。
         "writeMode": "truncate", # 当同名文件存在时系统进行的操作，可选值包括truncate、append和nonConflict，truncate表示会清理已存在的同名文件，append表示会加到已存在的同名文件内容后面，nonConflict表示当同名文件存在时会报错。
         "fileFormat": "csv", # 文件类型，可选值包括csv、txt和parquet格式。
         "encoding": "UTF-8", # 编码类型。
         "nullFormat": "null", # 定义null值的字符串标识符方式，可以是空字符串。
         "dateFormat": "yyyy-MM-dd HH:mm:ss", # # 时间格式。
         "fieldDelimiter": "," # 每一列的分隔符。
        }
        }
        }
        }
        ```

    4.  单击![save](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/7548388951/p127623.png)图标，保存数据源配置。

4.  运行同步任务。

    1.  单击![start](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/8548388951/p127635.png)图标。

    2.  在参数对话框，选择调度的资源组。

    3.  单击**确定**，开始运行任务。

        运行结束后，在运行日志页签中可以查看任务是否成功和导出的数据行数。

        表格存储的增量数据可以在延迟5~10分钟的基础上自动同步到OSS中。

5.  配置调度参数。

    通过**调度配置**，可以配置同步任务的执行时间、重跑属性、调度依赖等。

    1.  在**数据集成**节点下，双击同步任务节点。

    2.  在同步任务节点的编辑页面的右侧单击**调度配置**，进行调度参数配置，详情请参见[配置调度和依赖属性]()。

6.  提交同步任务。

    将同步任务提交到调度系统后，调度系统会根据配置的调度参数，自动定时执行同步任务。

    1.  在同步任务节点的编辑页面，单击![submit](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/8548388951/p127669.png)图标。

    2.  在提交新版本对话框，输入备注信息。

    3.  单击**确认**。


## 步骤四：查看同步任务

1.  进入运维中心。

    **说明：** 您也可以在DataStudio控制台的右上角单击**运维中心**，快速进入运维中心。

    1.  以项目管理员身份登录[DataWorks控制台](https://workbench.data.aliyun.com/console)。

    2.  选择地域，在左侧导航栏，单击工作空间列表。

    3.  在工作空间列表页面，单击工作空间操作区域的**进入运维中心**。

2.  在运维中心控制台，选择**周期任务运维** \> **周期任务**。

3.  在周期任务页面，查看提交的同步任务详情。

    -   在左侧导航栏中，选择**周期任务运维** \> **周期实例**，可以查看当天需要运行的周期任务。单击实例名称，可以查看任务运行详情。
    -   当单个任务在运行中或运行结束后，可以查看日志。

## 步骤五：查看导出到OSS中的数据

1.  登录[OSS管理控制台](https://oss.console.aliyun.com/)。

2.  选择相应Bucket和文件名，下载后可查看内容是否符合预期。


