# 全量同步加速 {#concept_1062539 .concept}

本文主要为您介绍在MySQL导入表格存储（Table Store）场景下，如何在DataX中加速全量数据的导出。

DataX的数据同步涉及三部分，每个部分都可以进行优化加速：

-   数据读取
-   数据交换
-   数据写入

## 数据读取 {#section_0ct_zmi_zax .section}

数据源读取有两种模式：table模式，sqlQuery模式。选择table模式可以加速读取，具体参见[步骤三：准备全量导出的JSON文件](cn.zh-CN/数据通道/将MySQL数据同步迁移到表格存储/全量同步.md#section_2lz_y13_r01)。

## 数据交换 {#section_d1k_yqd_7v5 .section}

在数据交换部分，可以从以下几个角度进行同步优化：

 **JVM的内存** 

发送给MySQL数据库SQL语句后会得到查询的数据集，并缓存在DataX的buffer中。除此之外，每个`channel`也维护了自己的`record`队列，如果存在并发，`channel`的个数越多，也会需要更多的内存。因此首先需要考虑的是JVM的内存大小参数，在[执行同步命令](cn.zh-CN/数据通道/将MySQL数据同步迁移到表格存储/全量同步.md#section_82d_436_4zb)时， `-j`参数可以用来指定JVM的内存大小。

 **channel的个数和流控参数** 

在conf/core.json中，控制`channel`有以下几个关键参数：

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/855910/156283051751151_zh-CN.png)

-   `capacity`：限制了`channel`中队列的大小（也就是最多缓存record的个数）
-   `byteCapacity`：限制了`record`占用的内存大小。
-   `byte`：控流参数，限制通道的默认传输速率， -1表示不限制。
-   `record`：控流参数，限制通道的传输记录数，-1表示不限制。

**说明：** 

-   一般情况下，`channel`队列本身配置的调整并不会很常见，但是在使用DataX的时候应该注意`byte`和`record`流控参数。这两个参数都是在flowControlInterval间隔里采样后根据采样值来决定是否流控的。
-   为了提升同步效率，可以适当提高`channel`的个数从而提高并发数，调高每个`channel`的`byte`和`record`限制，从而提高DataX的吞吐量。
-   请综合考量`channel`的个数和流控参数，保证理论峰值不会对服务器产生过高的压力。

`core.json`默认配置是64MB，若不指定将会被配置为8MB这两个参数决定了每个`channel`能缓存的记录数量和内存占用情况，如果有需要调整，用户应该按照DataX实际的运行环境予以配置。例如MySQL中每个`record`都比较大，那么可以考虑适当调高`byteCapacity`，当然调整这个参数还要考虑机器的内存情况。

``` {#codeblock_3hc_lui_1ju}
{
    "core": {  #定义了全局的系统参数，不指定会使用默认值
        "transport": {
            "channel": {
                "speed": {
                    "record": 5000,
                    "byte": 102400
                }
            }
        }
    },


    "job": {
        "setting": {
            "speed": {  #定义了单个channel的控制参数
                "record": 10000,
            },
            "errorLimit": {
                "record": 0,
                "percentage": 0.02
            }
        },
        "content": [
            {
                "reader": {
                      .....#省略
                },

                "writer": {
                    .....#省略
                }

            }
        ]
    }
}
```

## 数据写入 {#section_hci_tuf_jmq .section}

Table Store是基于LSM设计的高性能高吞吐的分布式数据库产品，每一张表，都会被切分成很多的数据分区，分布在不同的服务器上，拥有极强的吞吐能力。如果写入能够打散在所有的服务器上面，就能够利用所有服务器的服务能力，更高速地写入，也就是说表分区数量和吞吐能力是正相关的。

新建的表默认分区数量都是1，这个数目会随着表的不断写入自动分裂不断增长，但是自动分裂的周期较长，对于新建表马上进行数据导入的情况，单分区很可能不够用导致导入不够顺畅。 推荐的做法，一般是在建表的时候，对表进行预分区，这样可以在一开始导入的时候就获得极好的性能，而不用等自动分裂。

``` {#codeblock_ay4_f7x_f68}
{
    "job": {
        "setting": {
           ....#省略
        },
        "content": [
            {
                "reader": {
                      .....#省略
                },

                "writer": {
                    "name": "otswriter",
                    "parameter": {
                            .......
                        "writeMode":"UpdateRow",
                        "batchWriteCount":100
                    }
                }

            }
        ]
    }
}
			
```

